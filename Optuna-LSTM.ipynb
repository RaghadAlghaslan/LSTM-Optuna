{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be36efb-1d03-43f6-8bab-9a1067df59ce",
   "metadata": {},
   "source": [
    "# LSTM model using Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02941592-58f7-4a2a-abc3-19392d2cdc95",
   "metadata": {},
   "source": [
    "### Optuna is an open-source hyperparameter optimization (HPO) library for Python. It provides a framework for automating the process of finding the best hyperparameters for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee1dc7-725b-4c45-a0da-bcee53f743f3",
   "metadata": {},
   "source": [
    "#### After the dataset loading and preprocessing comes the model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a3d62-2928-47bd-a6d0-52ce63548939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fee4c0-2568-47bd-850a-acdb05848485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data frame into train and test\n",
    "\n",
    "# Determine the index to split the data\n",
    "split_index = int(len(df) * 0.8)  # Adjust the split ratio as needed\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = df.iloc[:split_index]\n",
    "test_data = df.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e438642-5ddb-443e-84de-8b86c5de7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into X and y\n",
    "X_train = train_data.drop('target_column', axis=1).values.astype(float) # Convert data types to float if needed\n",
    "y_train = train_data['target_column'].values\n",
    "\n",
    "# Split the testing set into X and y\n",
    "X_test = test_data.drop('target_column', axis=1).values.astype(float) # Convert data types to float if needed\n",
    "y_test = test_data['target_column'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1294fbfa-db47-4d90-b426-ec4e002b37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the set of batch_sizes numbers and set of epochs numbers to search \n",
    "batch_sizes = [16, 32, 64]\n",
    "epochs_values = [50, 100, 150]\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define other hyperparameters to optimize\n",
    "    units = trial.suggest_int('units', 32, 256) # Define the range of numbers \n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5, step=0.1) # Define the range of numbers\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True) # Define the range of numbers\n",
    "    \n",
    "    # Initialize variables to keep track of the best hyperparameters and MSE\n",
    "    best_mse = float('inf')\n",
    "    best_batch_size = None\n",
    "    best_epochs = None\n",
    "    \n",
    "    # Iterate over the combinations of batch_size and epochs_values\n",
    "    for batch_size in batch_sizes:\n",
    "        for epochs in epochs_values:\n",
    "            # Build the LSTM model with the current hyperparameters\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(units, input_shape=(X_train.shape[1], 1)))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "            model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "            \n",
    "            # Train the model\n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "            model.fit(X_train.reshape(X_train.shape[0], X_train.shape[1], 1),\n",
    "                      y_train,\n",
    "                      validation_split=0.2,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      callbacks=[early_stop],\n",
    "                      verbose=0)\n",
    "            \n",
    "            # Evaluate the model on the test set\n",
    "            y_pred = model.predict(X_test.reshape(X_test.shape[0], X_test.shape[1], 1))\n",
    "            mse = np.mean(np.square(y_test - y_pred))\n",
    "\n",
    "            # Check if the current hyperparameters yield a better MSE\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_batch_size = batch_size\n",
    "                best_epochs = epochs\n",
    "                print('Best Batch Size:', best_batch_size)\n",
    "                print('Best Epochs:', best_epochs)\n",
    "\n",
    "    return best_mse\n",
    "\n",
    "# Create and run the Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4e3d9-5a03-46eb-b131-80c684e07eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters and the corresponding MSE\n",
    "best_params = study.best_params\n",
    "best_mse = study.best_value\n",
    "print('Best Hyperparameters:', best_params)\n",
    "print('Best MSE:', best_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
